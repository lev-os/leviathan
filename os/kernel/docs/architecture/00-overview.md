# Architecture Overview

## Leviathan OS Kernel: AI-Native Operating System

### Vision
The world's first AI-controlled operating system where LLM serves as the decision engine, not just an assistant. Enhanced with pluggable discovery engines for autonomous learning and optimization.

## Core Architectural Principles

### 1. LLM-First Architecture
- AI reasoning as the primary execution engine
- System â†” LLM feedback loops for enhanced capabilities
- Autonomous decision-making and self-improvement
- Bootstrap sovereignty with minimal dependencies

### 2. Maximum Extensibility
- Plugin architecture enabling anyone to hack and extend
- Hot-swappable discovery engines at runtime
- Technical standards with freedom to innovate
- Community hackability by design

### 3. Emergent Intelligence
- Behavior emerges from system interaction and configuration
- Self-evolving workflows through trial-and-error learning
- Temporal memory for pattern recognition across time
- Zero-shot adaptation to new scenarios

## Revolutionary Innovations

### Pluggable Discovery Engine Architecture
**File**: `04-discovery-engine-architecture.md`

Core innovation: **TELO Cycle** (Trial-Error-Learn-Optimize)
- **SEAL Engine**: Self-evolving through synthetic data (MIT research)
- **JEPA Engine**: World model predictions (Meta research)  
- **Brute Force Engine**: Pure experimentation baseline
- **Hot-Swapping**: Runtime engine switching based on performance

### Temporal Memory Integration
**File**: `05-memory-integration-architecture.md`

Core innovation: **Graph + Vector Hybrid Memory**
- **Neo4j + Graphiti**: Temporal relationships and episodic memory
- **High-Quality Embeddings**: Voyage-3-large for semantic similarity
- **Workspace Isolation**: Engine-specific memory spaces
- **Cross-Engine Learning**: Shared insights with maintained boundaries

### Real Pattern Detection
**Implementation**: `src/pattern_detector.go`

Core innovation: **Mathematical Derivatives, Not Fake Confidence**
- CPU spike detection: Rate of change >20% per minute
- Memory leak detection: Consistent growth patterns
- Periodic pattern recognition: Interval similarity analysis
- Evidence-based confidence from actual data points

## Current Implementation Status

### âœ… Working (Phase 1 Complete)
- Real pattern detection with mathematical derivatives
- LLM-based predictions with validation loops
- 100-snapshot circular buffer for telemetry
- Basic JEPA 2 integration (needs enhancement)
- Project structure and documentation

### ðŸš§ In Progress (Phase 2)
- Discovery engine interface implementation
- Graphiti client for Neo4j integration
- High-quality embedding service
- BDD test suite for behaviors

### ðŸ“‹ Planned (Future Phases)
- Complete SEAL engine implementation
- Enhanced JEPA with real embeddings
- Runtime engine switching
- Performance monitoring and optimization

## Architecture Layers

### Layer 5: Discovery Engines (New)
**Revolutionary learning layer**
- SEAL: Self-evolving through synthetic data
- JEPA: World model temporal predictions
- Pluggable: Hot-swappable at runtime
- TELO: Universal learning cycle

### Layer 4: AI Decision Engine
- TinyLlama-driven autonomous optimization
- Pattern recognition and response
- Code generation and verification
- Resource management decisions

### Layer 3: Verified Dynamic Extensions
- eBPF programs generated by AI
- Multi-layer verification pipeline
- Real-time performance optimization
- Automatic rollback on failure

### Layer 2: Safe Plugin System
- WASM-based kernel extensions
- Capability-based isolation
- Portable device drivers
- Cross-platform compatibility

### Layer 1: Static Kernel Core
- C + Go hybrid foundation
- Hardware abstraction layer
- Memory management
- Core system services

## Key Design Decisions

### Why Pluggable Engines?
- **No single approach**: Different problems need different strategies
- **Research Platform**: Easy to test new discoveries (SEAL, JEPA, future)
- **Performance Optimization**: Switch to best engine for each problem type
- **Risk Mitigation**: Fallback options if advanced engines fail

### Why Graph + Vector Memory?
- **Temporal Relationships**: Neo4j for time-based connections
- **Semantic Search**: Vector embeddings for similarity
- **Workspace Isolation**: Separate experiments safely
- **Learning Persistence**: Knowledge survives system restarts

### Why Mathematical Pattern Detection?
- **Real Evidence**: Actual data points, not hardcoded confidence
- **Explainable**: Can show why pattern was detected
- **Reliable**: Consistent mathematical foundation
- **Extensible**: Easy to add new pattern types

## Development Philosophy

### BDD-First Development
- Define behaviors before implementation
- Self-documenting through tests
- Focus on outcomes, not implementation details
- Continuous validation of system behavior

### AI-Native Approach
- Always ask "Can an LLM do this?" before coding
- Use prompts and context over rigid frameworks
- Design for autonomous operation
- Enable system-LLM feedback loops

### Quality Over Speed
- High-quality embeddings (Voyage-3-large) for research
- Comprehensive testing and validation
- Proper separation of concerns
- Maintainable, extensible codebase

## Integration Points

### Claude Code Integration
- MCP protocol for tool access
- Session management across tabs
- Context preservation and restoration
- Hot-reload development support

### External Services
- **Neo4j**: Graph database (localhost:7687)
- **Qdrant**: Vector database for Go docs (localhost:6333)
- **Graphiti**: Temporal memory framework
- **Voyage API**: High-quality embeddings

## References

- **01-hybrid-design-fundamentals.md**: C/Go hybrid architecture
- **02-memory-management-design.md**: Memory safety strategies
- **03-ai-extensibility-framework.md**: AI-driven extensibility
- **04-discovery-engine-architecture.md**: TELO cycle and engines
- **05-memory-integration-architecture.md**: Graph + vector memory

---

*This overview provides the big picture. See individual architecture documents for detailed specifications and implementation guidance.*