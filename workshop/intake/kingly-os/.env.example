# Kingly OS Environment Configuration

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================

# Primary LLM Provider (simulation, transformers, openai, anthropic, groq, ollama, openrouter)
PRIMARY_LLM_PROVIDER=simulation
FALLBACK_LLM_PROVIDER=groq

# =============================================================================
# GROQ (Fast & Cheap - Great for Testing)
# =============================================================================
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-8b-instant
GROQ_BASE_URL=https://api.groq.com/openai/v1

# =============================================================================
# OPENROUTER (Multiple Models, Cheap Options)
# =============================================================================
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=meta-llama/llama-3.1-8b-instruct:free
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# =============================================================================
# OLLAMA (Local, Free) - FASTEST LOCAL MODELS
# =============================================================================
OLLAMA_BASE_URL=http://localhost:11434

# Ultra-fast tiny models for development
OLLAMA_MODEL=tinyllama          # 1.1B params - 637MB - Extremely fast
# OLLAMA_MODEL=smollm2          # 135M params - 80MB - Fastest inference
# OLLAMA_MODEL=qwen2:0.5b       # 0.5B params - 394MB - Good balance
# OLLAMA_MODEL=phi3.5:3.8b      # 3.8B params - 2.2GB - Better quality
# OLLAMA_MODEL=llama3.2:1b      # 1B params - 1.3GB - Fast & capable

# =============================================================================
# OPENAI (Premium)
# =============================================================================
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1

# =============================================================================
# ANTHROPIC (Premium)
# =============================================================================
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-haiku-20240307
ANTHROPIC_BASE_URL=https://api.anthropic.com

# =============================================================================
# KINGLY OS CONFIGURATION
# =============================================================================

# MCP Server Configuration
MCP_SERVER_PORT=3001
MCP_SERVER_HOST=localhost
MCP_ENABLE_BIDIRECTIONAL=true

# Learning Engine Settings
LEARNING_MODE_THRESHOLD=0.8
PATTERN_CONFIDENCE_THRESHOLD=0.7
MAX_EXPERIMENTS=5
EXPERIMENT_TIMEOUT=30000

# Context Assembly Settings
MAX_CONTEXT_TOKENS=8000
TOKEN_BUFFER_PERCENTAGE=0.1
DEFAULT_CONFIDENCE_THRESHOLD=0.6

# Development Settings
NODE_ENV=development
LOG_LEVEL=info
ENABLE_METRICS=true
ENABLE_LEARNING=true

# =============================================================================
# PROVIDER PRICING (for reference)
# =============================================================================
# GROQ: ~$0.10-0.27 per 1M tokens (very fast)
# OpenRouter: Free tier available, then ~$0.10+ per 1M tokens
# Ollama: Free (local)
# OpenAI GPT-4o-mini: ~$0.15-0.60 per 1M tokens
# Anthropic Claude Haiku: ~$0.25-1.25 per 1M tokens