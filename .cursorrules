# Leviathan Cursor Rules

This project uses modular cursor rules for better organization and context-aware assistance.

## üìÇ Modular Rules Location: `.cursor/rules/`

### Core Rules

- **`global-architecture.mdc`** - Core principles (always applied)
- **`javascript-agent-development.mdc`** - Agent development patterns
- **`plugin-development.mdc`** - Plugin creation guidelines
- **`ide-integration-patterns.mdc`** - IDE/Cursor integration helpers
- **`flowmind-bidirectional-workflows.mdc`** - Advanced workflow patterns
- **`go-kernel-development.mdc`** - Go kernel patterns
- **`web-integration-patterns.mdc`** - Web app integration

## üöÄ Quick Start Commands

```bash
# Show all available commands
lev help

# Search for thinking patterns
lev context search "synthesis"
lev context search "decision making"

# Start a work session
lev checkpoint --new "working on <feature>"

# Apply a thinking pattern
lev context apply echo-intelligence-patterns

# Run a workflow
lev workflow run document-synthesis
```

## üèóÔ∏è Architecture Overview

**Leviathan** is an AI-native operating system - the "Linux of AI":

- **Hexagonal Architecture**: Strict separation of business logic and adapters
- **MCP Protocol**: Bi-directional LLM communication
- **Plugin Ecosystem**: Everything extensible via `@lev-os/` plugins
- **Context-First**: Thinking patterns and workflows drive behavior

## üéØ Core Development Principles

### 1. LLM-First Architecture

```javascript
// ALWAYS ask: "Can an LLM do this?" before writing code
// Example: Instead of parsing logic, use semantic evaluation
async function evaluateCondition(condition, context) {
  // ‚ùå WRONG: Complex parsing logic
  // ‚úÖ RIGHT: Let LLM evaluate semantically
  return await llm.evaluate(`Does "${condition}" apply in context: ${JSON.stringify(context)}?`)
}
```

### 2. Maximum Extensibility (Linux of AI)

- Everything is a plugin that can be replaced/extended
- Use `@lev-os/` namespace for all plugins
- Auto-bootstrap pattern for zero-configuration
- Community can hack and extend any component

### 3. Bi-Directional Communication Architecture

```javascript
// The Inversion of Control Pattern:
// 1. LLM ‚Üí System Call: Agent identifies need
// 2. System ‚Üí LLM Response: System provides workflow + callback
// 3. LLM ‚Üí Enhanced Processing: LLM executes with full context
// 4. LLM ‚Üí System Callback: LLM reports results
// 5. System ‚Üí Iteration: System saves progress, guides next step
```

### 4. Constitutional Principles

1. **Bootstrap Sovereignty**: Minimal dependencies, maximum autonomy
2. **Emergent Intelligence**: Behavior emerges from system interaction
3. **Context-First**: Context defines behavior and capabilities
4. **Session Continuity**: Quantum context entanglement across Claude tabs
5. **FlowMind Integration**: Natural language ‚Üí executable workflows

## üìÅ Project Structure & Conventions

### Directory Structure

```
leviathan/
‚îú‚îÄ‚îÄ agent/              # Core MCP server & agent system (JavaScript)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands/   # Hexagonal core - business logic only
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ adapters/   # CLI & MCP adapters - routing only
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ core/       # Shared services & registries
‚îÇ   ‚îî‚îÄ‚îÄ contexts/       # YAML-driven workflows & patterns
‚îú‚îÄ‚îÄ plugins/@lev-os/    # Published npm packages
‚îú‚îÄ‚îÄ os/                 # AI-native OS components (Go + Python)
‚îÇ   ‚îú‚îÄ‚îÄ kernel/src/     # Go-based AI decision engine
‚îÇ   ‚îî‚îÄ‚îÄ agent/          # Python semantic search & JEPA 2
‚îú‚îÄ‚îÄ apps/               # Application layer
‚îî‚îÄ‚îÄ _ref/               # Reference implementations (FlowMind, etc.)
```

### Hexagonal Architecture Pattern

```javascript
// ‚úÖ CORRECT: Command with pure business logic
// src/commands/example-command.js
export async function exampleCommand(args, dependencies) {
  const { semanticLookup, workflowLoader } = dependencies
  // Pure business logic here
  return { success: true, data: result }
}

// MCP tool export for auto-discovery
export const exampleCommandTool = {
  name: 'example_command',
  description: exampleCommand.description,
  inputSchema: exampleCommand.inputSchema,
  handler: exampleCommand,
}

// ‚ùå WRONG: Mixing adapters with business logic
// Adapters should ONLY route, core should ONLY compute
```

### Plugin Development Standards

```javascript
// plugins/@lev-os/example-plugin/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ plugin.yaml     # YAML-first configuration
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ commands/       # Auto-discovered commands
‚îÇ   ‚îî‚îÄ‚îÄ index.js        # Plugin entry point
‚îî‚îÄ‚îÄ tests/              # Comprehensive test coverage

// Command pattern for auto-bootstrap
export async function myCommand(args, dependencies) {
  // Implementation
}

myCommand.description = "Command description";
myCommand.inputSchema = { /* JSON Schema */ };

// MCP tool export (required for bi-directional flow)
export const myCommandTool = {
  name: 'my_command',
  description: myCommand.description,
  inputSchema: myCommand.inputSchema,
  handler: myCommand
};
```

## üîÑ Bi-Directional MCP Workflow Pattern

### FlowMind Constitutional Framework

```javascript
// FUNDAMENTAL TRUTH: THE LLM IS THE RUNTIME
// FlowMind contexts CONFIGURE the LLM's behavior

// Context switching creates emergent intelligence:
// Step 1: LLM calls MCP ‚Üí "Execute workflow step 1"
// Step 2: MCP loads context ‚Üí "You are NFJ-Visionary. Analyze..."
// Step 3: LLM reasons with MAXIMUM POWER as NFJ-Visionary
// Step 4: LLM callback ‚Üí "Here are my visionary insights..."
// Step 5: MCP loads NEW context ‚Üí "You are STP-Adapter. Pragmatize..."
// [CYCLE CONTINUES...]
```

### Implementing Bi-Directional Workflows

```javascript
// Using Mastra-inspired patterns with MCP
export async function executeWorkflow(args, dependencies) {
  const { workflowId, step = 1, previousResults, challenge } = args

  // Load FlowMind context
  const workflow = await dependencies.workflowLoader.load(workflowId)

  // Execute current step with context injection
  const stepConfig = workflow.steps[step - 1]
  const contextInjection = {
    personality: stepConfig.agent,
    systemPrompt: stepConfig.prompt,
    previousResults,
    challenge,
  }

  // Return instructions for LLM to execute
  return {
    type: 'workflow_step',
    workflow: { id: workflowId, currentStep: step },
    contextInjection,
    callbackInstruction: `After completing this step, call execute_workflow with step=${step + 1}`,
  }
}
```

### Mastra/XState Integration Pattern

```javascript
// Workflow control flow APIs (Mastra-inspired)
class WorkflowBuilder {
  step(name, handler) {
    // Create workflow step with MCP callback
    return this
  }

  then(handler) {
    // Chain sequential steps
    return this
  }

  after(branches) {
    // Merge parallel branches
    return this
  }

  suspend(condition) {
    // Pause for human-in-the-loop via MCP
    return this
  }

  resume(sessionId) {
    // Continue from suspension point
    return this
  }
}
```

## üß™ Testing Standards

### Test Structure

```javascript
// Use @lev-os/testing framework
import { runLevCommand, callMCPTool } from '@lev-os/testing'

describe('Feature Integration', () => {
  test('CLI and MCP produce identical results', async () => {
    const cliResult = await runLevCommand(['command', 'arg'])
    const mcpResult = await callMCPTool('command', { arg: 'arg' })
    expect(cliResult.data).toEqual(mcpResult.data)
  })
})
```

### Testing Principles

- Test bi-directional flow with real MCP calls
- Validate CLI ‚Üî MCP adapter consistency
- Use session management for stateful tests
- Never mock LLM reasoning - use real evaluation

## üöÄ Development Workflow

### Session Management

```bash
# Start new session
lev checkpoint --new "implementing feature X"

# Continue work across Claude tabs
lev checkpoint --resume

# Create session rollup for handoff
lev checkpoint --final
```

### Command Development Flow

1. Create command in `src/commands/`
2. Implement pure business logic
3. Export MCP tool definition
4. Test via both CLI and MCP
5. Validate bi-directional flow

### Environment Setup

```bash
# Required services
docker run -d --name qdrant -p 6333:6333 qdrant/qdrant:latest
docker run -d --name neo4j -p 7687:7687 neo4j:latest

# Environment variables
ANTHROPIC_API_KEY=your_key
OPENAI_API_KEY=your_key
OLLAMA_URL=http://localhost:11434
```

## üé® Code Style & Patterns

### JavaScript/TypeScript Guidelines

```javascript
// Use ES modules throughout
import { feature } from './module.js'

// Async/await over promises
async function operation() {
  const result = await asyncCall()
  return result
}

// Destructure dependencies
export async function command(args, { service1, service2 }) {
  // Use injected dependencies
}

// Metadata for auto-discovery
command.description = 'Clear description'
command.inputSchema = {
  /* JSON Schema */
}
```

### Go Guidelines (os/kernel)

```go
// AI-native patterns
type LLMDecisionEngine struct {
    parliament *CognitiveParliament
    flowmind   *FlowMindParser
    jepa       *JEPA2WorldModel
}

// Use context for cancellation
func (e *LLMDecisionEngine) Analyze(ctx context.Context) error {
    // Implementation
}
```

### YAML-First Configuration

```yaml
metadata:
  id: my-context
  type: workflow
  name: 'Human Readable Name'

workflow_config:
  steps:
    - name: 'Visionary Analysis'
      agent: nfj-visionary
      prompt_file: prompts/visionary.md

triggers:
  semantic: 'when user needs strategic planning'
```

## üîê Security & Performance

### Security Principles

- Validate all LLM outputs before execution
- Use sandboxed environments for code generation
- Implement rate limiting for API calls
- Secure credential management via environment

### Performance Optimization

- Cache semantic embeddings aggressively
- Use streaming for long-running operations
- Implement circuit breakers for external services
- Profile memory usage with large contexts

## üìö Integration Patterns

### Browser Automation (browser-use)

```javascript
// Integrate browser-use for web interactions
import { Agent } from 'browser-use'

export async function webResearch(args, dependencies) {
  const agent = new Agent({
    task: args.query,
    llm: dependencies.llm,
  })

  const result = await agent.run()

  // Return in MCP-compatible format
  return {
    type: 'web_research',
    data: result,
    callbackInstruction: 'Process research results',
  }
}
```

### Vercel AI SDK Integration

```javascript
// For chat UI exposing agent capabilities
import { streamText } from 'ai'

export async function streamAgentResponse(prompt, { llm }) {
  const stream = await streamText({
    model: llm,
    system: 'You are a Leviathan agent with access to MCP tools',
    prompt,
    tools: mcpTools, // Auto-discovered tools
  })

  return stream
}
```

## üéØ Production Considerations

### Deployment

- Use Docker for service dependencies
- Environment-based configuration
- Health checks for all services
- Graceful shutdown handling

### Monitoring

```javascript
// Use @lev-os/debug for observability
import { logger, tracer, monitor } from '@lev-os/debug'

export async function monitoredOperation() {
  const span = tracer.startSpan('operation')
  try {
    const result = await operation()
    span.setStatus({ code: 'ok' })
    return result
  } catch (error) {
    logger.error('Operation failed', { error })
    span.setStatus({ code: 'error' })
    throw error
  } finally {
    span.end()
  }
}
```

### Error Handling

- Always provide context in errors
- Use structured error types
- Implement retry logic for transient failures
- Log errors with full context

## ü§ù Contributing Guidelines

### Code Review Checklist

- [ ] Follows hexagonal architecture
- [ ] Includes MCP tool export
- [ ] Has comprehensive tests
- [ ] Uses dependency injection
- [ ] Implements bi-directional flow
- [ ] Follows naming conventions
- [ ] Updates documentation

### Pull Request Template

```markdown
## Description

Brief description of changes

## Type of Change

- [ ] Bug fix
- [ ] New feature
- [ ] Breaking change
- [ ] Documentation update

## Testing

- [ ] CLI adapter tested
- [ ] MCP adapter tested
- [ ] Bi-directional flow validated
- [ ] Integration tests pass

## Checklist

- [ ] Follows constitutional principles
- [ ] Uses @lev-os/ namespace
- [ ] Includes proper error handling
- [ ] Updates relevant documentation
```

## üîÆ Future Patterns (In Development)

### JEPA 2 World Model Integration

```javascript
// Predictive intelligence and autonomous optimization
export async function predictiveAnalysis(context, { jepaModel }) {
  const prediction = await jepaModel.predict({
    currentState: context,
    timeHorizon: '4D', // space + time + code + context
  })

  return {
    prediction,
    confidence: prediction.confidence,
    suggestedActions: prediction.actions,
  }
}
```

### Quantum Context Entanglement

```javascript
// Cross-tab session synchronization
export async function entangleContext(sessionId, { quantum }) {
  const entanglement = await quantum.createEntanglement(sessionId)

  return {
    primarySession: sessionId,
    entangledSessions: entanglement.sessions,
    sharedState: entanglement.state,
  }
}
```

---

**Remember**: Every line of code should ENABLE the LLM, not REPLACE it. The LLM is the runtime, FlowMind orchestrates the intelligence that already exists.
